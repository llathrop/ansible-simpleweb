# Ansible Simple Web Interface

A lightweight, Docker-based web interface for managing and executing Ansible playbooks. Run playbooks with a single click, monitor execution status in real-time, and view logs through a clean, modern web UI.

## Features

### Core Features
- ðŸš€ **One-Click Execution** - Run any playbook with a single button click
- ðŸŽ¯ **Multi-Host Support** - Target individual hosts or groups via dropdown selection
- ðŸ“Š **Real-Time Status** - Live status updates (Ready/Running/Completed/Failed)
- ðŸ“ **Log Management** - Automatic log capture with timestamped filenames
- ðŸ” **Log Viewer** - Browse and view all execution logs in the browser
- ðŸŽ¨ **Theming Support** - Multiple themes including dark mode, low contrast, and colorblind-friendly options
- ðŸ”Œ **REST API** - JSON endpoints for external integrations
- ðŸ³ **Fully Containerized** - Rocky Linux 9 with Ansible 8.7.0 pre-configured
- ðŸ”’ **Localhost First** - Secure by default, ready for authentication later
- ðŸ’¾ **Flexible Storage** - Choose between flat file (JSON) or MongoDB for data persistence
- ðŸ“¦ **Inventory Management** - API for managing host inventory with full CRUD operations

### Batch Job Execution
- ðŸ“¦ **Batch Jobs** - Select multiple playbooks and hosts, run them sequentially as a named batch
- ðŸ”„ **Playbook Ordering** - Drag-and-drop or up/down buttons to reorder playbook execution
- ðŸ‘ï¸ **Live Batch Monitoring** - Watch batch progress with automatic log switching between playbooks
- ðŸ“¡ **Real-time Log Streaming** - Worker logs stream live to batch view with late-join catchup
- ðŸ“¤ **Export Configurations** - Export batch job configs as JSON for version control
- â° **Batch Scheduling** - Schedule batch jobs with full recurrence options

### Schedule Management
- â±ï¸ **Playbook Scheduling** - Schedule single playbooks or batch jobs with cron-like recurrence
- ðŸ“ˆ **Success Rate Tracking** - Track success/failure rates per schedule (e.g., "8/10 succeeded")
- ðŸ“‹ **Execution History** - View detailed history of scheduled runs

### Host Configuration Wizard
- ðŸ§™ **Multi-Step Wizard** - Guided 4-step process for adding/editing hosts
- ðŸ”‘ **SSH Key Management** - Upload and manage SSH private keys securely
- ðŸ” **Multiple Auth Methods** - Support for SSH keys, passwords, or SSH agent
- ðŸ” **Connection Testing** - Test SSH connectivity before saving host configuration

### AI Agent (Log Review & Assistance)
- ðŸ¤– **Automatic Log Review** - AI analyzes playbook output after each run
- ðŸ“‹ **Structured Analysis** - Summary, status, issues (error/warning/info), suggestions
- ðŸ”§ **Suggested Fix** - SSH auth failures show step-by-step fix with public key and Copy button
- ðŸ“Š **Agent Dashboard** - Recent reviews, proposals, config reports

## Quick Start

### Prerequisites
- Docker
- docker-compose
- SSH server on target hosts

### 1. Start the Container

```bash
# Clone or navigate to project directory
cd ansible-simpleweb

# Build and start (full stack: web + optional MongoDB, agent, workers)
docker-compose up -d

# Verify it's running
docker-compose ps
```

**Single image / demo:** To run only the primary container (no DB, agent, or workers), build the image and use the single-container compose file. See **Single-container (demo) mode** in `docs/REBUILD.md` and the **Single-container and expansion workflow** there for initial config, bootstrap, and adding workers later.

### 2. Access the Web Interface

Open your browser to: **http://localhost:3001**

You'll see all available playbooks with run buttons and status indicators.

### 3. Run Your First Playbook

1. Select a target from the dropdown (e.g., "host_machine")
2. Click "Run Playbook"
3. Watch the status change to "Running"
4. Click "View Log" when complete

Done! ðŸŽ‰

## Adding Playbooks

Simply drop a `.yml` file in the `playbooks/` directory:

```bash
# Create a new playbook
cat > playbooks/my-playbook.yml << 'EOF'
---
- name: My Custom Playbook
  hosts: all
  gather_facts: yes
  tasks:
    - name: Collect information
      debug:
        msg: "Running on {{ ansible_hostname }}"
EOF

# Refresh the web interface - it appears automatically!
```

**That's it!** No restart needed, no configuration required.

## Adding Hosts

Edit `inventory/hosts` to add new target machines:

```ini
[production]
prod1.example.com ansible_user=deploy
prod2.example.com ansible_user=deploy

[staging]
stage.example.com ansible_user=deploy
```

Refresh the page - new hosts appear in the dropdown automatically.

## Project Structure

```
ansible-simpleweb/
â”œâ”€â”€ playbooks/          # Add your Ansible playbooks here
â”œâ”€â”€ inventory/          # Configure target hosts here
â”‚   â””â”€â”€ hosts          # Main inventory file (Ansible INI format)
â”œâ”€â”€ logs/              # Playbook execution logs (auto-generated)
â”œâ”€â”€ ssh-keys/          # Uploaded SSH private keys (writable)
â”œâ”€â”€ .ssh/              # System SSH keys (read-only mount)
â”œâ”€â”€ config/            # Configuration files
â”‚   â”œâ”€â”€ themes/        # Theme JSON files (customizable)
â”‚   â”œâ”€â”€ schedules.json # Schedule definitions (flatfile backend)
â”‚   â”œâ”€â”€ schedule_history.json # Execution history (flatfile backend)
â”‚   â”œâ”€â”€ inventory.json # Managed inventory (flatfile backend)
â”‚   â”œâ”€â”€ batch_jobs.json # Batch job records (flatfile backend)
â”‚   â”œâ”€â”€ workers.json   # Worker registry (flatfile backend)
â”‚   â””â”€â”€ jobs.json      # Job queue (flatfile backend)
â”œâ”€â”€ web/               # Flask web application (primary server)
â”‚   â”œâ”€â”€ app.py         # Main Flask application (~4700 lines)
â”‚   â”œâ”€â”€ scheduler.py   # APScheduler integration (batch + single schedules)
â”‚   â”œâ”€â”€ job_router.py  # Smart job routing with tag-based targeting
â”‚   â”œâ”€â”€ content_repo.py # Git content repository management
â”‚   â”œâ”€â”€ storage/       # Storage backend abstraction
â”‚   â”‚   â”œâ”€â”€ __init__.py    # Factory function
â”‚   â”‚   â”œâ”€â”€ base.py        # Abstract interface (workers, jobs, inventory, schedules)
â”‚   â”‚   â”œâ”€â”€ flatfile.py    # JSON file storage
â”‚   â”‚   â””â”€â”€ mongodb.py     # MongoDB storage
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ index.html         # Batch execution page (main)
â”‚   â”‚   â”œâ”€â”€ playbooks.html     # Individual playbook cards
â”‚   â”‚   â”œâ”€â”€ schedules.html     # Schedule management
â”‚   â”‚   â”œâ”€â”€ inventory.html     # CMDB with host wizard
â”‚   â”‚   â”œâ”€â”€ cluster.html       # Cluster dashboard
â”‚   â”‚   â”œâ”€â”€ job_status.html    # Live job status with log streaming
â”‚   â”‚   â””â”€â”€ batch_live_log.html # Live batch job monitoring
â”‚   â””â”€â”€ static/
â”œâ”€â”€ worker/            # Worker service (runs on worker nodes)
â”‚   â”œâ”€â”€ __main__.py    # Worker entry point
â”‚   â”œâ”€â”€ service.py     # Main worker service loop
â”‚   â”œâ”€â”€ config.py      # Worker configuration
â”‚   â”œâ”€â”€ api_client.py  # Primary server API client
â”‚   â”œâ”€â”€ executor.py    # Ansible playbook executor
â”‚   â”œâ”€â”€ sync.py        # Content sync from primary
â”‚   â””â”€â”€ sync_notify.py # WebSocket sync notifications
â”œâ”€â”€ agent/             # AI agent (log review, playbook generation)
â”‚   â”œâ”€â”€ service.py     # Flask agent service
â”‚   â”œâ”€â”€ llm_client.py  # LLM (Ollama) client
â”‚   â”œâ”€â”€ prompts.yaml   # Prompts for log review, playbook gen
â”‚   â””â”€â”€ rag.py         # RAG / vector store for context
â”œâ”€â”€ tests/             # Test suite (93+ tests)
â”œâ”€â”€ docs/              # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md  # Single architecture reference (components, workflows, logs)
â”‚   â””â”€â”€ CLUSTER.md     # Cluster architecture guide
â”œâ”€â”€ Dockerfile.worker  # Worker container image
â””â”€â”€ docker-compose.yml # Primary + workers + MongoDB
```

## Documentation

- **[Architecture](docs/ARCHITECTURE.md)** - Single reference: components, workflows, logs and debugging (including agent)
- **Agent (LLM)**: Ollama runs **only in the `ollama` container** (do not run Ollama on the host). Default model is `qwen2.5-coder:3b`; use `1.5b` for lightest, `7b` for best quality. Change via `LLM_MODEL` in agent-service env. Pull: `docker compose exec -T ollama ollama pull qwen2.5-coder:3b`. Verify: `./scripts/verify-ollama.sh`. Logs: `docker compose logs ollama`.
- **[Usage Guide](docs/USAGE.md)** - Detailed interface walkthrough
- **[Adding Playbooks](docs/ADDING_PLAYBOOKS.md)** - Complete guide to creating playbooks
- **[Configuration](docs/CONFIGURATION.md)** - Inventory setup and SSH configuration
- **[API Reference](docs/API.md)** - REST API endpoints
- **[Troubleshooting](docs/TROUBLESHOOTING.md)** - Common issues and solutions

## Current Playbooks

Example playbooks included:

**General (Linux/Unix)**
- **hardware-inventory** - CPU, memory, disks, GPU detection
- **software-inventory** - Installed packages with versions
- **system-health** - Uptime, load, memory, disk usage, errors
- **service-status** - System services and their status
- **network-config** - Network interfaces, routing, DNS
- **disk-usage-analyzer** - Disk space analysis
- **change-user-password** - Change user password

**MikroTik RouterOS**
- **mikrotik-router-check** - Basic RouterOS connectivity check
- **collect_stats_routeros** - Collect stats from RouterOS
- **get_config_routeros** - Retrieve RouterOS configuration

## Development Status

âœ… **Step 1:** Docker container with Ansible + Flask
âœ… **Step 2:** 5 working playbooks tested on real hardware
âœ… **Step 3:** Full web interface with real-time updates
âœ… **Step 4:** Multi-host target selection
âœ… **Step 5:** Theming system with dark mode and accessibility themes
âœ… **Step 6:** Pluggable storage backend (flat file / MongoDB)
âœ… **Step 7:** Batch job execution with live monitoring
âœ… **Step 8:** Schedule management with batch support and success tracking
âœ… **Step 9:** Host configuration wizard with SSH key management
âœ… **Step 10:** Cluster mode with distributed workers (13 features implemented)
  - Worker registration and authentication
  - Content repository with revision tracking
  - Sync API for playbook/inventory distribution
  - Worker service with health reporting
  - Job queue with priority support
  - Smart job routing with tag-based targeting
  - Worker execution with log capture
  - Worker check-in and heartbeat monitoring
  - Job completion reporting with log upload
  - Sync notification via WebSocket
  - Local executor fallback
  - Cluster dashboard with real-time stats

**Status:** Cluster mode fully functional with comprehensive test coverage (93+ tests for cluster features)

## Common Commands

```bash
# Start the service
docker-compose up -d

# View logs
docker-compose logs -f

# Restart after changes
docker-compose restart

# Stop the service
docker-compose down

# Run playbook manually (from host)
docker-compose exec -T ansible-web ansible-playbook playbooks/your-playbook.yml -l target
```

## Requirements

- Docker Engine 20.10+
- docker-compose 1.29+
- 2GB RAM minimum
- Network access to target hosts

## Security Notes

- Currently **localhost only** (no external access)
- No authentication required (add before exposing externally)
- SSH keys mounted read-only from `~/.ssh`
- Service account recommended for target hosts (see [Configuration](docs/CONFIGURATION.md))

## Cluster Mode (NEW)

Distribute Ansible workloads across multiple worker nodes for scalability and fault tolerance.

### Cluster Features
- ðŸ”— **Worker Registration** - Workers auto-register with primary server using tokens
- ðŸ“Š **Worker Dashboard** - Real-time view of all workers with health stats
- âš–ï¸ **Smart Job Routing** - Automatic job assignment based on tags, load, and preferences
- ðŸ”„ **Content Sync** - Playbooks/inventory sync from primary to workers with revision tracking
- ðŸ“¡ **Real-time Updates** - WebSocket notifications for sync events
- ðŸ·ï¸ **Tag-Based Targeting** - Route jobs to specific workers via required/preferred tags
- ðŸ’“ **Health Monitoring** - Worker check-ins with CPU, memory, and disk stats
- ðŸ–¥ï¸ **Local Executor Fallback** - Built-in local worker as lowest-priority fallback

### Quick Cluster Setup

```bash
# Start cluster with 3 workers
docker-compose up -d

# Verify workers registered
curl http://localhost:3001/api/workers | python3 -m json.tool
```

### Cluster Architecture
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Primary Server â”‚
                    â”‚  (ansible-web)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
        â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Worker-1    â”‚  â”‚   Worker-2    â”‚  â”‚   Worker-3    â”‚
â”‚  zone-a       â”‚  â”‚  zone-b       â”‚  â”‚  zone-c       â”‚
â”‚  general      â”‚  â”‚  high-memory  â”‚  â”‚  network      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
See [Architecture](docs/ARCHITECTURE.md) and [CLUSTER.md](docs/CLUSTER.md) for the full system and cluster detail.

---

## Future Enhancements

### Infrastructure Improvements
- Mount inventory file to workers for target host access
- Configure SSH agent forwarding for workers
- Add health check endpoint to worker Dockerfile
- Support custom ansible.cfg per worker
- Support external workers (not in Docker network)

### Security
- Rotate registration tokens periodically
- Add TLS between workers and primary
- Implement job result signing/verification
- Add worker authentication beyond token
- Add authentication system (JWT, OAuth, or basic auth)
- User management and role-based access control

### Job Management
- Job cancellation (kill running playbook on worker)
- Job retry with configurable attempts
- Job timeout handling
- Job priority queuing (high/normal/low)

### Worker Management
- Manual worker enable/disable from dashboard
- Worker maintenance mode (drain jobs before shutdown)
- Worker auto-scaling based on queue depth
- Worker groups/pools for isolation

### Monitoring
- Prometheus metrics endpoint
- Grafana dashboard templates
- Alert rules for worker failures
- Job queue depth monitoring
- Host health monitoring
- Performance metrics (execution time trends)

### User Experience
- Email notifications on playbook completion
- Slack/Teams/Discord webhook integrations
- Mobile app or PWA support
- Variable substitution in playbooks via UI
- Conditional execution based on previous results
- Ansible Vault integration

### Documentation
- Video walkthrough/tutorial
- Interactive demo environment
- Community playbook repository
- Best practices guide for playbook authors

### Contribution Ideas

Have an idea for improvement? Consider:
1. Adding new example playbooks to `playbooks/`
2. Improving documentation with real-world examples
3. Creating integration guides for popular tools
4. Submitting bug reports or feature requests

## License

Internal use only.

## Contributing

This project uses git for version control. Each significant change is committed with descriptive messages.

## Support

For issues or questions:
1. Check [Troubleshooting Guide](docs/TROUBLESHOOTING.md)
2. Review [Usage Documentation](docs/USAGE.md)
3. Check application logs: `docker-compose logs`

---

**Built with Claude Code** | Generated with Claude Opus 4.5
